{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Metric\n",
    "\n",
    "Loss - 학습 데이터를 바탕으로 게산, 파라미터 업데이트에 활용  \n",
    "Metric - 훈련 데이터를 바탕으로 계산, 학습된 모델의 성능 평가에 활용  \n",
    "\n",
    "Accuracy 와 Cross Entropy  \n",
    "\n",
    "- Accuracy는 0과 1 분류에 따른 정확도 값  \n",
    "- Cross Entropy는 target class에 가까울수록 낮은 Loss(손실)을 부여함\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4가지 지표\n",
    "\n",
    "- Acc Score - 참이든 거짓이든 얼마나 정확하게 예측했느냐  \n",
    "- Precision - `참으로 예측`한 것 중에서 `실제 참`이 얼마나 되느냐  \n",
    "- Recall - `실제 참`인 것들 중 `참으로 예측해 맞춘 경우`가 얼마나 되느냐  \n",
    "\n",
    "- F1-score - Precision과 Recall만으로 평가하기 어려운 문제를 위해 Precision과 Recall의 조화평균을 사용\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Convolution Layer\n",
    "\n",
    "기존 Convolution, 원본 데이터 손실이 지나치지 않은가?  \n",
    "\n",
    "`Auto Encoder` Convolution 결과를 역재생하여 원본 이미지와 최대한 유사한 정보를 복원\n",
    "- 데이터: 압축 후 복원이기 때문에, X_train 자신이 정답 Label이 됨\n",
    "- Encoder와 Decoder로 구성  \n",
    "- Shape을 변형시키는 것은 Convolution 레이어가 아니라, pooling & upscaling 레이어\n",
    "- 복원한 이미지 결과가 썩 좋지 않다. Transposed Convolution을 흉내낸 것에 불과함  \n",
    "\n",
    "`Upsampling` 이미 버린 정보를 복원하는 법?\n",
    "- Nearest Neighbor - 가까운 값으로 복제  \n",
    "- Bed of Nails - 복원할 값을 0으로 처리  \n",
    "- Max Unpooling - Max Pooling 때 버린 값을 따로 기억해두었다가 그 값으로 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_conv_layer_1 = Conv2D(16, (3, 3), activation='relu')\n",
    "encode_pool_layer_1 = MaxPooling2D((2, 2))\n",
    "encode_conv_layer_2 = Conv2D(8, (3, 3), activation='relu')\n",
    "encode_pool_layer_2 = MaxPooling2D((2, 2))\n",
    "encode_conv_layer_3 = Conv2D(4, (3, 3), activation='relu')\n",
    "\n",
    "encoded = encode_conv_layer_1(input_img)\n",
    "encoded = encode_pool_layer_1(encoded)\n",
    "encoded = encode_conv_layer_2(encoded)\n",
    "encoded = encode_pool_layer_2(encoded)\n",
    "encoded = encode_conv_layer_3(encoded)\n",
    "\n",
    "# AutoEncoder 모델 구성 - Decoder 부분 -\n",
    "decode_conv_layer_1 = Conv2DTranspose(4, (3, 3), activation='relu', padding='same')\n",
    "decode_upsample_layer_1 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_2 = Conv2DTranspose(8, (3, 3), activation='relu', padding='same')\n",
    "decode_upsample_layer_2 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_3 = Conv2DTranspose(16, (3, 3), activation='relu')\n",
    "decode_upsample_layer_3 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_4 = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')\n",
    "\n",
    "decoded = decode_conv_layer_1(encoded) # Decoder는 Encoder의 출력을 입력으로 받습니다.\n",
    "decoded = decode_upsample_layer_1(decoded)\n",
    "decoded = decode_conv_layer_2(decoded)\n",
    "decoded = decode_upsample_layer_2(decoded)\n",
    "decoded = decode_conv_layer_3(decoded)\n",
    "decoded = decode_upsample_layer_3(decoded)\n",
    "decoded = decode_conv_layer_4(decoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
